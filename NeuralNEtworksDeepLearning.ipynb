{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 1: Neural networks and deep learning\n",
    "---\n",
    "*Responsible:* Guillermo Hamity (<ghamity@ed.ac.uk>)\n",
    "\n",
    "In this checkpoint exercise, we will use neural networks to predict the **type** of weather *given* the available ground observations. You will be using observation data from **June 2019** across all UK Met Office weather stations.\n",
    "\n",
    "### Notes on the Dataset\n",
    "* You will be using weather observation data from the UK Met Office Datapoint service\n",
    "* Ground observations are made hourly at weather stations across the length of the UK \n",
    "* The data sample covers data from June 2019\n",
    "* Data collections for each day starts at 6.30pm. All observation data is listed in one day blocks\n",
    "* The time value column refers to the number of minutes after midnight \n",
    "* `Null` values for some features are expected (e.g. Wind Gust)\n",
    "* Data import and preparation is already provided \n",
    "\n",
    "\n",
    "This week, I am not providing example notebooks like `lecture2.ipynb` and `data-science-tools.ipynb` for Unit 2, though these may still be useful to you. Instead, I am **providing the imports for all of the modules and classes that you should need.** Think of these as LEGO blocks; you have the ones you need but may look up how to \"assemble\" them.\n",
    "\n",
    "### Notes on assessment\n",
    "* Try and calculate the answers to the exercises provided. If you are unable to complete the question, describe which approach you _would_ have taken to solve the problem\n",
    "* Code must be understandable and reproducible. Before grading the notebook kernel **may** be restarted and re-run, so make sure that your code can run from start to finish without any (unintentional) errors\n",
    "* If you are unsure on how to proceed please **ask one of the TAs** during the workshop\n",
    "- Notebooks should be submitted by **10am on Friday 9 October 2021** \n",
    "- This CP exercise sheet is divided into **6 sections**, corresponding to parts of the lecture, giving a maximum of **10 marks** in total:\n",
    "\n",
    "| <p align='left'> Title                         | <p align='left'> Exercise nos. | <p align='left'> Number of marks |\n",
    "| ------------------------------------- | ----- | --- |\n",
    "| <p align='left'> 1. Conceptual questions               | <p align='left'>  1–5  | <p align='left'> 3 |\n",
    "| <p align='left'> 2. Data preprocessing and RandomForest                | <p align='left'>  6–9  | <p align='left'> 2. |\n",
    "| <p align='left'> 3. Neural networks in `scikit-learn`  | <p align='left'>  10–11 | <p align='left'> 1.5 | \n",
    "| <p align='left'> 4. Neural networks in `Keras`         | <p align='left'> 12–13 | <p align='left'> 2 |\n",
    "| <p align='left'> 5. Regularisation                     | <p align='left'> 14–15 | <p align='left'> 1.5 |\n",
    "| <p align='left'> **Total** | | <p align='left'> **10** |\n",
    "\n",
    "- The total number of marks allocated for this CP is 10,\n",
    "    - 1 additional mark can be given (maximimally up to 10 marks in total) for \"bonus\" exercise on hyperparameter optimisation. If you are pressed for time, focus on the first five sections; those are the core ones.\n",
    "    - Half marks may be deducted for code legibility (i.e. very difficult to tell what you are doing), or for badly formated plots (i.e. no legends, axis labels etc.). The TAs will use their discression for this so comment code when applicable and keep relevant information in your plots.\n",
    "\n",
    "_Note:_ You can suppress double-printing of plots from the `plot` module by either _(a)_ adding a semicolon after the function call (_i.e._ `plot.<method>(...);`), or _(b)_ by capturing the return `pyplot.Figure` object as a variable (_i.e._ `fig = plot.<method>(...)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard import(s)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress unnecessary ConvergenceWarnings and DeprecationWarnings\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "# Set a random seed variable to make workbook reproducible\n",
    "seed=5\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "# Switch off multi-threading for TensorFlow\n",
    "from tensorflow.python.keras import backend as K\n",
    "config = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                                  inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the prepared weather data\n",
    "obs = pd.read_csv('weather.csv')\n",
    "obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape \n",
    "obs.shape\n",
    "obs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we will use **8** input features (provided) and clean the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 8 input feature variables, 1 target variable data, and names of the 3 weather types\n",
    "features = ['Latitude', 'Elevation', 'Temperature', 'Visibility', 'WindSpeed', 'Pressure', 'Humidity', 'WindDirection']\n",
    "output   = ['Type']\n",
    "wtype    = ['Clear', 'Cloudy', 'Precip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define derived dataset containing only the relevant columns and rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to feature and type columns\n",
    "dataset = obs[features + output]\n",
    "\n",
    "# Drop duplicates and null values \n",
    "dataset = dataset.drop_duplicates().dropna()\n",
    "\n",
    "# Drop unrecorded weather type\n",
    "dataset = dataset[dataset.Type != 3]\n",
    "\n",
    "# Check shape \n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Conceptual questions (3 Marks)\n",
    "---\n",
    "This section covers **5** exercises on conceptual understanding of neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Which are the most used activation functions and why do we (typically) need non-linear activation functions in neural networks? (0.5 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most used activation functions are Sigmoid activation, ReLu, Softmax, and tanh.\n",
    "We usually need non-linear activation functions in neural networks because the hidden layers are not useful when using linear activation functions (the composition of linear functions is itself a linear function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, a non-linear activation function permits the stacking of multiple layers of neurons (in order to create the deep neural network) allowing the subequent layers to build off each other. It can be thought as if you put two consecutive linear layers they have the same power as a single linear layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Why do we need deep neural networks and which are the main differences between deep and shallow learning? (0.5 Mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With deep learning (deep NN) the performance increases when you increse the amount of data (this is because it doesn't just only predicts an ouput Y from an input X, but it also understande basic features of the input, being able to make abstractions of the features of the input and to make predictions based on those characteristics). This abstraction component is not found in shallow lwearning algorithm. Also, with other algorithms, the performance gets better when increasing the amount of data but only up to a constat performance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With normal shallow learning we are not able to explot high dimensional data (we can do that with deep learning). With shallow learning we have a manual feature engeneering (we don't have that component with deep learning). With shallow learning we use simple algorithms to obtain the output, while with dep learning they don't have to be simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other characteristics of deep learning that are not found in shallow learning are that: - the network can learn relevant features. - It can perform feature extraction and deep combination simultaneously. - It performs feature selection to find the best subset of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Discuss the Bias-variance trade-off and its relation to underfitting and overfitting of a model. Which are the caractheristics of an ideal model?  (0.5 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias-variance trade-off is a fundamental principle for understanding the generalization of predictive learning power. The absic idea is that in a mdoel there is a tradeoff between the model's ability to minimize bias and variance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias is the difference between the average prediction of our model and the correct value which we are trying to predict.\n",
    "Variance is the variability of model prediction for a given data point or a value which tells us spread of our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underfitting model: The model does not have enough capacity/flexibility. It has high bias, meaning hat it is a model with poor performance on training data. This model cannot learn relevant structure in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting model: The model has too much capacity/flexibility. In this case the errors have high variance, hence the model shows low losses on training but high losses on testing dataset. It basically overfits as it learns random structure in data set that does not represents a generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideal model: Sufficient capacity/flexibility. The model basically learns levant structure in dataset with good generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Given a neural network with 4 input nodes, 2 layers with 5 nodes each, and 1 output node, what is the total number of free (trainable) parameters in the network? Does it matter which activation function(s) are used?  (0.5 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this neural network is densely connected then we can calulate 61 trainable parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function that is chosen does not change the number of trainable parameters. However, that choice will impact other thingsm like the performance of the network we are constructing or the capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. What are appropriate choice for _(a)_ the number of output nodes and _(b)_ output activation function(s) for each of the following tasks, and why? (0.5 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Regression of the $x$, $y$, and $z$ coordinates of a single particle in an arbitrary coordinate system\n",
    "\n",
    "Activation function: ReLu -- Nodes: 3 ouput layers (3 - axis, arbitrary space coordinates )\n",
    "\n",
    "2. Regression of particle energy of a single particle\n",
    "\n",
    "Activation function: ReLu -- Nodes: 1 ouput layer (energy goes from 0 to infinity)\n",
    "\n",
    "3. Classification of two processes (signal vs. background)\n",
    "\n",
    "Activation function: Sigmoid -- Nodes: 2 output layers  (discriminator)\n",
    "\n",
    "4. Classification among *N* classes (dog vs. cat vs. fish vs. ...)\n",
    "\n",
    "Activation function: Softmax -- Nodes: N ouput layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6. Given some data points and regression/classification problem, write the appropite cost function and compare your solution to that from sklearn (0.5 marks)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression** \n",
    "\n",
    "A good **loss function** for regression is the **Mean Squared Error**. \n",
    "\n",
    "For $N$ samples with targets $Y$, our prediction $\\bar{Y}$ has an MSE of:\n",
    "\n",
    "\n",
    "$\\mathrm{MSE} = \\frac{\\sum[(\\bar{Y}-Y)^2]}{N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics # Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regression Problem\n",
    "\n",
    "# 3 Targets for regression \n",
    "Y = np.array([0.,1.,0.5])\n",
    "# 3 Predicted values (at random)\n",
    "YPred = np.random.rand(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost function (Mean Square Error):\n",
    "def mse(YPred,Y):\n",
    "\n",
    "    N = Y.shape[0]\n",
    "    mse_res = np.sum((YPred - Y)**2)/N\n",
    "    \n",
    "    return mse_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing our function to the sklearn MSE\n",
    "prediction = np.random.rand(Y.shape[0])\n",
    "print (\"My MSE function is {}\".format(\"Correct\" if mse(prediction,Y) == metrics.mean_squared_error(prediction,Y) else \"Wrong\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification**\n",
    "\n",
    "Log Loss from the lecture notes is appropiate for binary classification, where our prediction is a probaility of `label = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 Random class labels (0 or 1)\n",
    "Y = np.random.randint(0,2,10)\n",
    "# 10 Random Probabilities\n",
    "YPred = np.random.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(YPred,Y):\n",
    "    N = Y.shape[0]   \n",
    "    logloss_res = (-1/N)*np.sum((Y*np.log(YPred) + (1-Y)*np.log(1-YPred)))\n",
    "    \n",
    "    return  logloss_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check it matches the sklearn log_loss\n",
    "logloss(YPred,Y) == metrics.log_loss(Y.astype(int),YPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing and RTs (2 mark)\n",
    "---\n",
    "This section covers **4** exercises on data preparation, feature standardisation, and dataset splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant import(s) for this section\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics # Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import preprocessing # Import preprocessing for String-Int conversion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**_Comment on target format and one-hot encoding:_** By default, the target column (`Type`) contains one integer (0, 1, or 2) for each example, the integer specifying one of three possible types of weather. However, for doing multi-class classification (which this is), we want our neural network to have one output node per class (_i.e._ 3 output nodes in this case), such that the activation of each output node is interpreted as the likelihood for a given sample being of the type in question. Therefore, the target should also be a 3-element vector for each sample; this vector should be all zeros, except for a $1$ at the index corresponding to the type in question. This is called **one-hot encoding**, and a few examples are shown below:\n",
    "\n",
    "- type = 0 $\\to$ one-hot = $[1, 0, 0]$ for 3 classes\n",
    "- type = 1 $\\to$ one-hot = $[0, 1, 0]$ for 3 classes\n",
    "- type = 2 $\\to$ one-hot = $[0, 0, 1]$ for 3 classes\n",
    "\n",
    "This is the target towards which a neural network classifier is trained: That is, ideally, for an example of type 0, the network will output a large activation ($\\approx 1$) on the first output node (interpreted as a large likelihood for the first weather type), and very small activations ($\\ll 1$) on the two other output nodes (intepreted as small likelihoods for the two other weather types); and so on.\n",
    "\n",
    "The same type of one-hot encoding can be performed for any number of target classes $N_{c}$, which just results in $N_{c}$-element target vectors with a single non-zero entry each.\n",
    "\n",
    "To be user friendly, however, `scikit-learn` allows us to use integer targets for multi-class classification — it does the one-hot encoding for us \"under the hood.\" Similarly, `keras`, _can_ also allow us to use integer targets for multi-class classification, provided we use the appropropriate loss (`sparse_categorical_crossentropy`). Otherwise (if we use `categorical_crossentropy` loss), it expects one-hot encoded targets. Which approach you choose is up to you — but now you know what goes on.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Prepare the feature and target arrays (0.5 mark)\n",
    "- Randomly sample **3,500** observations per weather type (**10,500** observations in total) from `dataset` into a new `pandas.DataFrame`; call it `sample`.\n",
    "- One-hot encode the **wind direction** variable (_i.e._ $N$ to $[1, 0, \\ldots, 0]$, $NNE$ to $[0, 1, \\ldots, 0]$, _etc._ ), to allow us to input it to the neural network. There are 16 unique directions so we need to transform 1 feature into 16 features.\n",
    "The exact order of the encoding (_i.e._ which direction corresponds to which index) doesn't matter. *Hint:*\n",
    "  - *Either:* Use the scikit-learn `ColumnTransformer` with the `OneHotEncoder` applied to the `WindDirection` column, and let the remainder of the features pass through un-transformed.\n",
    "  - *Or:* Use the `OneHotEncoder` class directly on the `WindDirection` column (use `sparse=False` in the `OneHotEncoder` constructor), and then concatenate with a `numpy.array` containing the remaining features.\n",
    "- Define `numpy.arrays` named `X` and `y` containing the training features (the 7 unmodified ones plus the one-hot encoded wind directions) and target, respectively.\n",
    "- Argue whether the shapes of `X` and `y` are as expected/as they should be.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For convenience concatenate the wind direction and other features \n",
    "# in the order that you can use this feature name variable\n",
    "feature_names = list(range(16))+features[:-1]\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sampling 3500 observations per weather type\n",
    "sample = dataset.groupby([\"Type\"]).sample(n=3500)\n",
    "sample[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding the 'WindDirection' variable\n",
    "# 16 unique directions\n",
    "wind_trans = ColumnTransformer([('OneHotW', OneHotEncoder(), ['WindDirection']),],remainder='passthrough')\n",
    "\n",
    "X = wind_trans.fit_transform(sample[features]) \n",
    "y = sample['Type'].values\n",
    "\n",
    "print(X.shape)\n",
    "#explain Y.shape and X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The array has the expected shape:\n",
    "# ROWS: 3x3500 = 10500 samples from the random sampling (target value: Weather Typer).\n",
    "# COLUMNS: the 7 untransformed features plus the 16 transformed features (from the hotencoding) minus winddirection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Train a Random Forest, evaluate performance, explore features (1.5 mark)\n",
    "\n",
    "Decision trees work well with a mixture of features (of different scales, and both binary and continuous data), so we will train a random forest to do the job of categorisation.\n",
    "\n",
    "You are given the train test split (70% training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import random fosets and confusion matrix metric\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# split dataset into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "print(x_train.shape,x_test.shape,y_train.ravel().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a `RandomForestClassifier` with a `GridSearchCV` over the following input parameters to the mode'. Split the dataset into only 3 cross validation folds to make it a little faster (Hint: see `GreidSearchCV` function documentation)\n",
    "2. Check the overal accuaracy on the testing set\n",
    "3. What is the best set of hyperparametrs the scan has found? \n",
    "\n",
    "*Hint:* the final random forest that is chosen can be returned with th the `best_estimator_` member of the `GridSearchCV` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We scan a broad range of parameters to use for the RandomForest\n",
    "rf_dic={\n",
    "    \"n_estimators\":[10,50,200,500],\n",
    "    \"max_features\": [\"sqrt\",\"log2\"],\n",
    "    \"criterion\": [\"gini\"],\n",
    "    \"max_depth\": [4,8,30]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing GridSearchCV, data splitted into 3 cross validation folds\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), rf_dic, n_jobs=7, cv=3)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall accuracy \n",
    "y_pred = grid_search.predict(x_train)\n",
    "print(\"Accuracy Training:\",metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(\"Accuracy Testing:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best set of hyperparameters: \",grid_search.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding Classification Accuracy**\n",
    "\n",
    "4. Use the `confusion_matrix` method on the **test data** to return the confusion matrix normalised over the true lables, i.e. sum over rows should sum to 100%. Use the given colormap to plot the confusion matrix in a heatmap.\n",
    "    - Define the axis tick names to represent Clear, Cloudy or Precip\n",
    "    - Use suitable x and y axis labels\n",
    "    \n",
    "5. What are the true positive rates for clear, cloudy and perp? \n",
    "6. What is the probability that rain is forcast on a sunny day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = metrics.confusion_matrix(y_test, y_pred, normalize='true')\n",
    "\n",
    "colormap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "display_labels = ['clear', 'cloudy', 'precipitation']\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# Generate Heat Map, allow annotations and place floats in map\n",
    "sns.heatmap(test_matrix, cmap=colormap, annot=True, fmt=\".2f\", xticklabels=display_labels, yticklabels=display_labels)\n",
    "plt.title(\"Confussion Matrix: Understanding some weather probabilities.\")\n",
    "plt.ylabel(\"Normalised probability (true)\")\n",
    "plt.xlabel(\"Normalised probability (predicted)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of rain on a sunny day (clear day) is of only 2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Understanding Feature Importance**\n",
    "\n",
    "There are several ways to understand which **features are important** to the \n",
    "decision tree. The most common is to look at `feature_importances_` list which is calculated at training time. This quantifies by how much each feature splits the dataset, the higher the number, the more imporant the feature. In random forests were we have 100s of trees, the importance is an gregate.\n",
    "\n",
    "\n",
    "*Note:* below the code assumes the random forest CV search is still `grid_search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given plotting example for feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.barh(range(23), grid_search.best_estimator_.feature_importances_)\n",
    "ax.set_yticks(list(range(23)))\n",
    "ax.set_yticklabels(feature_names)\n",
    "ax.set_title(\"Training Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g. In the RF I trained, wind direction has little impact on the performance, while Pressure, Visibility and Humidity seem like natural important features.\n",
    "\n",
    "The problem with `feature_importances_` is that they are **calulated and biased towards the training dataset**, so may not represent the most relevant features for classifying on the **testing dataset**.\n",
    "\n",
    "\n",
    "We can use `permutation_importance` to get a more accurate representation on the feature importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will randomly permute (shuffle) one feature at a time, and look at how much the accuracy changes. We can perform this permutation several times (`n_repeats`) and get an average impact on the accuracy, and a std deviation.\n",
    "\n",
    "7. Complete the permutation importance function below\n",
    "    - Use the test dataset\n",
    "    - Permute each feature 20 times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(grid_search, X, y, n_repeats=20\n",
    "    , random_state=42, n_jobs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Make the feature importance plot as above using \n",
    "    - `result.importances_mean` as the feature importances\n",
    "    - `result.importances_std` for the `barh` parameter `xerr=`\n",
    "    - Comment on how the imporatnces change on the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.barh(range(23), result.importances_mean, xerr=result.importances_std)\n",
    "ax.set_yticks(list(range(23)))\n",
    "ax.set_yticklabels(feature_names)\n",
    "ax.set_title(\"Features importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Finally we can look at the impact of individual features on the probablity of a **particular class**.\n",
    "\n",
    "Using `PartialDependenceDisplay` we choose a set of features that we allow to vary within a range, while other features remain fixed. We can look at how the probability estimate changes on average for any one of our targets. \n",
    "\n",
    "9. Complete the `PartialDependenceDisplay.from_estimator` function by:\n",
    "    - adding your random forest estimator\n",
    "    - using the first 100 data points of the test dataset as input\n",
    "    - Use the `Humidity`, `Pressure` and `Visibility` features. These feature values are scanned while the others remain fixed (*Hint:* `features` parameter)\n",
    "    - Look at the impact on the `Precipitaion` class probability (*Hint:* `target` parameter)\n",
    "10. Comment on the trends shown over the 3 features on the probability it will rain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set_title(\"Decision Tree\")\n",
    "tree = PartialDependenceDisplay.from_estimator(grid_search, x_test, features= [19,21,22], feature_names = feature_names, target = 2,ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots show: the less visibility the more probable is to rain, the lower the pressure the more probable is to rain, and the more humidity the most probable is to rain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural networks in `scikit-learn` (1.5 mark)\n",
    "---\n",
    "This section covers exercises on constructing and training neural networks using the `scikit-learn` library, as well as evaluating neural network performance. `scikit-learn` provide many, very easy to use ML algorithms, including neural networks. These are called `MLPClassifier` (MLP = multi-layer perceptron; a historic name for densely connected, feed-forward neural networks) when used for classification, and `MLPRegressor` when used for regression. We will focus on the former for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant import(s) for this section\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Standardise the relevant features  and split data (0.5 mark)\n",
    "We need some additional processing of the input features to make them appropiate for the neural network. \n",
    "\n",
    "- Use our feature array `X`, and standardize the features.\n",
    "\n",
    "    _Note:_ You shouldn't standardise the one-hot encoded wind directions; they already have the desired format. Perform a sanity check to make sure that the resulting features have the expected distributional properties (mean and standard deviation; or minimum and maximum value).\n",
    "    - Hint:\n",
    "\n",
    "        - Use the scikit-learn `StandardScaler`\n",
    "        - Or use the scikit-learn `MinMaxScaler`\n",
    "\n",
    "- Perform a sanity check to make sure that the resulting features have the expected distributional properties (mean and standard deviation; or minimum and maximum value).\n",
    "    - The number of columns should match, and depending on the choice of standardisation, the last 7 columns should either have:\n",
    "      - (Using `StandardScaler`) means = 0 and standard deviations = 1; or\n",
    "      - (Using `MinMaxScaler`) min = 0, max = 1\n",
    "      \n",
    "- Reserve **30%** of data for testing. Check whether the resulting arrays have the expected shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarize the features of the array \n",
    "X[:,16:] = StandardScaler().fit_transform(X[:,16:]) \n",
    "\n",
    "# Check that mean has to be 0 and the standard deviation 1\n",
    "print(X[:,17].mean())\n",
    "print(X[:,17].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data sets in 0.7 and 0.3\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "print(x_train.shape,\n",
    "x_test.shape,\n",
    "y_test.shape,\n",
    "y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapes as expected (total 10500, 70% -> 7350, 30% -> 3150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Construct, train, and evaluate a neural network  (1 mark)\n",
    "\n",
    "- Create an `MLPClassifier` which\n",
    "    - has **1 hidden layer of 50 neurons** \n",
    "    - has **no regularization term**\n",
    "    - trains for a maximum of **100 epochs** \n",
    "    - uses a batch size of **32**\n",
    "- Fit the classifier using the standard `.fit()` member method.\n",
    "- Plot the loss function value as a function of number of epochs (0.5 of mark).\n",
    "  You can access the loss history through the `.loss_curve_` attribute of the `MLPClassifier` instance. \n",
    "\n",
    "- Using the testing dataset: \n",
    "    - Compute the overall accuracy for the classifier using the `MLPClassifier`'s `.score()` member method for both testing and training datasets.\n",
    "    - Compute the confusion matrix (normalised in true labels), and plot it \n",
    "- Discuss the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(50,), batch_size=32, max_iter=100, alpha=0).fit(x_train, y_train)\n",
    "plt.xlabel(\"Number of trainning epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(clf.loss_curve_)\n",
    "\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(clf, X, y, normalize='true', display_labels = ['clear', 'cloudy', 'precipitation'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trainning accuracy: \", clf.score(x_train, y_train)) #Accuracy trainning\n",
    "print(\"Testing accuracy: \",clf.score(x_test, y_test)) #Accuracy test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural networks in `Keras` (2 marks)\n",
    "---\n",
    "This section covers exercises on constructing and training neural networks using the `Keras` library. `scikit-learn` is very easy to use, but libraries like `Keras` provide a lot more flexibility, which is why we will be using these extensively in the last two units of the _'Data science tools and machine learning'_ track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant import(s) for this section\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Construct a neural network in `Keras` (1 mark)\n",
    "\n",
    "- Create a `keras.Model` using the **Keras functional API**. The network should have:\n",
    "    - An input layer with the same number of nodes as the number of features in `X`.\n",
    "    - A single, densely connected hidden layer with **50 nodes** equipped with **ReLU activation**.\n",
    "    - A densely connected output layer with **3 nodes** (the number of types of weather we're classifying) equipped with **softmax activation**.\n",
    "- Compile the model the using the **Adam optimiser**, add `'accuracy'` as metric, and use either:\n",
    "    - `categorical_crossentropy` loss, if you have one-hot encoded the targets `y`, or\n",
    "    - `sparse_categorical_crossentropy` loss if you hare using integer-valued targets.\n",
    "- Use the `.summary()` member method to print an overview of the model you have created, explain the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network \n",
    "input = Input(shape=(23,))\n",
    "x = Dense(50, activation=\"relu\")(input) #x name of the hidden layer\n",
    "output = Dense(3,activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(input, output)\n",
    "model.compile(\"adam\", loss=\"sparse_categorical_crossentropy\", metrics = \"accuracy\" )\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Train a `Keras` neural network (1 mark)\n",
    "\n",
    "- Use the `.fit()` member method to train the network on the **training dataset** for **100 epochs** with a **batch size of 32**. Use **20% of the data for validation** and make sure to have `Keras` **shuffle** the training data between epochs. Save the fit history by doing `history_mld = .....`\n",
    "- Print the classification accuracy using the `.evaluate()` member method, for both the training and testing dataset. Comment on the results.\n",
    "- Plot val_loss and loss functions from the fit history. On the same plot, plot the sklearn curve from the excercise above. Note the sklearn NN does not provide a complementary validation loss history, so only plot the training loss.\n",
    "- Comment on the results of the overall accuracy compared to the scikit-learn method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_mdl = model.fit(x_train, y_train, epochs=100, batch_size=32, shuffle=True, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history_mdl.model.evaluate(x_train, y_train)) #Accuracy trainning (if you want to show only the accuracy use [1])\n",
    "print(history_mdl.model.evaluate(x_test, y_test)) #Accuracy test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot val_loss and loss functions from the fit history. On the same plot, plot the sklearn curve from the excercise above. Note the sklearn NN does not provide a complementary validation loss history, so only plot the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_mdl.history['loss'], label = \"Keras Loss\")\n",
    "plt.plot(history_mdl.history['val_loss'], label = \"Keras Validation Loss\")\n",
    "plt.plot(clf.loss_curve_, label = \"Sklearn loss\")\n",
    "plt.xlabel(\"Number of trainning epochs\")\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Regularisation (1.5 marks)\n",
    "---\n",
    "This section covers **2** exercises on the impact of weight regularisaton. Note that $L_{1}$- and $L_{2}$-regularisation may also be applied to the activation of intermediate layers. Also, a similar regularising effect could be achieved using **dropout** regularisation, which you are encouraged to try out, but which we won't study in this CP exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant import(s) for this section\n",
    "from tensorflow.python.keras.regularizers import l1_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Define `Keras` model factory method (0.5 mark)\n",
    "\n",
    "- Define a python function called `big_model_fn` which takes the followng three arguments:\n",
    "    - `l1`: A float specifying the $L_{1}$ regularisation factor (default value: 0)\n",
    "    - `l2`: A float specifying the $L_{2}$ regularisation factor (default value: 0)\n",
    "    - `name`: A string, specifying the name of the model (default value: None)\n",
    "- Indside the function, you should:\n",
    "    - Construct a `Keras` model using the functional API, which has:\n",
    "        - An input layer with the same number of nodes as the number of features in `X`.\n",
    "        - **Two** densely connected hidden layer with **100 nodes** each, both equipped with **ReLU activation**.\n",
    "        - Both hidden layers should be subject to kernel regularisation (_i.e._ weight regularisation) with the regularisation factors specified as an input.\n",
    "        - A densely connected output layer with **3 nodes** (the number of types of weather we're classifying) equipped with **softmax activation**.\n",
    "        - A name given by the corresponding argument.\n",
    "    - Compile the model in the same way as in **Exercise 14.**\n",
    "- The function should return the compiled `Keras` model. \n",
    "\n",
    "The method will provide a convenient way of constructing and compiling a number of \"big\"/deep `Keras` models which differ only by their regularisation and name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_model_fn(l1=0, l2=0, name=None):\n",
    "\n",
    "    input = Input(shape=(23,))\n",
    "    X_A = Dense(100, activation=\"relu\", kernel_regularizer= \"l1_l2\")(input)\n",
    "    X_B = Dense(100, activation = \"relu\",kernel_regularizer= \"l1_l2\")(X_A) \n",
    "    output = Dense(3,activation=\"softmax\")(X_B)\n",
    "    model = Model(input, output, name=name)\n",
    "    \n",
    "\n",
    "    model.compile(\"adam\", loss=\"sparse_categorical_crossentropy\", metrics = \"accuracy\" )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Train \"big\" models with and without regularisation (1 mark)\n",
    "\n",
    "- Construct three \"big\" model using the factory method:\n",
    "     - One with default parameters\n",
    "     - One with `l1=0.003` and  `name='model_L1'`\n",
    "     - One with `l2=0.03`  and `name='model_L2'`\n",
    "- Train each one as in **Exercise 15.**\n",
    "- Compare first the loss history of the un-regularised \"big\" model to that of the small model from **Exercise 15** using the `plot.loss()` method.\n",
    "- Then, compare the loss histories of all three \"big\" models with that of the small model.\n",
    "- Plot the loss and val loss of all 4 models. Target these points:\n",
    "    - Compare the performance of deep vs shallow models on the testing sets\n",
    "    - Compare the level of ovetraining (training vs testing loss)\n",
    "    - Note: Don't be alarmed if the shallow network performs slightly better that the deeper ones, this is dataset dependant.\n",
    "- Copy the same plotting code, but this time plot the training and validation accuracy\n",
    "- Discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = big_model_fn().fit(x_train, y_train, epochs=100, batch_size=32, shuffle=True, validation_split = 0.2)\n",
    "model_L1 = big_model_fn(l1=0.003, name= \"model_L1\").fit(x_train, y_train, epochs=100, batch_size=32, shuffle=True, validation_split = 0.2)\n",
    "model_L2 = big_model_fn(l2= 0.03,name= \"model_L2\").fit(x_train, y_train, epochs=100, batch_size=32, shuffle=True, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare first the loss history of the un-regularised \"big\" model to that of the small model from **Exercise 15** using the `plot.loss()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_mdl.history['loss'], label = \"Keras Loss\")\n",
    "plt.plot(default.history['loss'], label = \"Default Loss\")\n",
    "plt.xlabel(\"Number of trainning epochs\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then, compare the loss histories of all three \"big\" models with that of the small model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_mdl.history['loss'], label = \"Keras Loss\")\n",
    "plt.plot(default.history['loss'], label = \"Default Loss\")\n",
    "plt.plot(model_L1.history['loss'], label = \"Model_L1 Loss\")\n",
    "plt.plot(model_L2.history['loss'], label = \"Model_L2 Loss\")\n",
    "plt.plot(history_mdl.history['val_loss'], label = \"Keras val_Loss\")\n",
    "plt.plot(default.history['val_loss'], label = \"Default val_Loss\")\n",
    "plt.plot(model_L1.history['val_loss'], label = \"Model_L1 val_Loss\")\n",
    "plt.plot(model_L2.history['val_loss'], label = \"Model_L2 val_Loss\")\n",
    "plt.xlabel(\"Number of trainning epochs\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_mdl.history['accuracy'], label = \"Keras trainning accuracy\")\n",
    "plt.plot(default.history['accuracy'], label = \"Default trainning accuracy\")\n",
    "plt.plot(model_L1.history['accuracy'], label = \"Model_L1 trainning accuracy\")\n",
    "plt.plot(model_L2.history['accuracy'], label = \"Model_L2 trainning accuracy\")\n",
    "plt.plot(history_mdl.history['val_accuracy'], label = \"Keras val_accuracy\")\n",
    "plt.plot(default.history['val_accuracy'], label = \"Default val_accuracy\")\n",
    "plt.plot(model_L1.history['val_accuracy'], label = \"Model_L1 val_accuracy\")\n",
    "plt.plot(model_L2.history['val_accuracy'], label = \"Model_L2 val_accuracy\")\n",
    "plt.xlabel(\"Number of trainning epochs\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('daml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa8f7fdf83b5f1ccd18250a318def58717bab35df4bdf7bdaa576d57998f1146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
